{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bottle_detection_code .ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyO8/2Ghk1EHzbt3Fi5/3PrK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ubUsE7qtMWfj","colab_type":"text"},"source":["\n","### **Inroduction**:\n","\n","\n","Aiming to minimize police response time by detecting weapons in a live cctv camera. The main motivation of this project is due to the increasing number of school mass shootings in the U.S.\n","\n","\n","### This notebook is a part of this [medium post](https://medium.com/@alaasinjab/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d)."]},{"cell_type":"markdown","metadata":{"id":"Yi0JMo0RNT2Y","colab_type":"text"},"source":["### This notebook was designed to be ran from top to bottom without the need to mount Google Drive"]},{"cell_type":"markdown","metadata":{"id":"65t7YUhnzDCE","colab_type":"text"},"source":["## Weapon Detection Using Tensorflow Object Detection API"]},{"cell_type":"markdown","metadata":{"id":"CWrRz3kXDksW","colab_type":"text"},"source":["Workspace structure\n","\n","```\n","gun_detection/\n","        ├─ data/\n","        │    ├── images/\n","        │    │      ├── armas (1).jpg\n","        │    │      ├── armas (2).jpg\n","        │    │      └── ...\n","        │    ├── train_labels/\n","        │    │      ├── armas (1).xml\n","        │    │      ├── armas (2).xml\n","        │    │      └── ...\n","        │    ├── test_labels/\n","        │    │      ├── armas (10).xml\n","        │    │      ├── armas (20).xml\n","        │    │      └── ...\n","        │    ├── label_map.pbtxt\n","        │    ├── test_labels.csv\n","        │    ├── train_labels.csv\n","        │    ├── test_labels.record\n","        │    └── train_labels.record\n","        └─ models/\n","             ├─ research/\n","             │      ├── fine_tuned_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── pretrained_model/\n","             │      │         ├── frozen_inference_graph.pb\n","             │      │         └── ...\n","             │      │         \n","             │      ├── object_detection/\n","             │      │         ├── utils/\n","             │      │         ├── samples/\n","             │      │         │      ├── samples/ \n","             │      │         │      │       ├── configs/             \n","             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n","             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n","             │      │         │      │       │     └── ...\n","             │      │         │      │       └── ... \n","             │      │         │      └── ...                                \n","             │      │         ├── export_inference_graph.py\n","             │      │         ├── model_main.py\n","             │      │         └── ...\n","             │      │         \n","             │      ├── training/\n","             │      │         ├── events.out.tfevents.xxxxx\n","             │      │         └── ...               \n","             │      └── ...\n","             └── ...\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"J2TS8TVWvs3N","colab_type":"code","outputId":"bed6b51f-eb64-44b7-e36d-96eece277a90","executionInfo":{"status":"ok","timestamp":1589968965976,"user_tz":-120,"elapsed":105554,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":887}},"source":["!pip install tensorflow==1.15.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 36.5MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 37.0MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.29.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (46.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=3a0b7ece15e3d81a0bf612c9f97e3f8518cd0765703066ff73c736cdc2efc251\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorflow 2.2.0\n","    Uninstalling tensorflow-2.2.0:\n","      Successfully uninstalled tensorflow-2.2.0\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cLgzXHXcAig4","colab_type":"code","outputId":"eff79206-6409-4862-ef1c-09fe86b189af","executionInfo":{"status":"ok","timestamp":1589968972720,"user_tz":-120,"elapsed":2687,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AMlXJ2yIV8e7","colab_type":"text"},"source":["## Choosing a pre training model\n","The model used for this project is `ssd_mobilenet_v2_coco`.\n","Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n","\n","Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"]},{"cell_type":"code","metadata":{"id":"j3_Ns54i3HgO","colab_type":"code","colab":{}},"source":["\n","\n","# Some models to train on\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","    }\n","}\n","\n","# Select a model in `MODELS_CONFIG`.\n","# I chose ssd_mobilenet_v2 for this project, you could choose any\n","selected_model = 'ssd_mobilenet_v2'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sv3Zm042QGJy","colab_type":"text"},"source":["## Installing Required Packages "]},{"cell_type":"code","metadata":{"id":"68StUELaQPS2","colab_type":"code","outputId":"46aaada7-fd79-40f7-e757-e38659a2e96e","executionInfo":{"status":"ok","timestamp":1589969003125,"user_tz":-120,"elapsed":23293,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"source":["!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -qq pycocotools"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 144433 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ERyocH9U-o2Y","colab_type":"text"},"source":["## General imports\n","Other Imports will be done after downloading some packages later."]},{"cell_type":"code","metadata":{"id":"CEVLeKXh-s23","colab_type":"code","colab":{}},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import cv2 \n","import os\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","import io\n","import tensorflow as tf\n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","import shutil\n","import urllib.request\n","import tarfile\n","\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8QeHvX6gpmC","colab_type":"code","outputId":"4c9b44ea-84ce-4e4b-e52e-747ff5961e5f","executionInfo":{"status":"ok","timestamp":1589969003860,"user_tz":-120,"elapsed":23998,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n","print(tf.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sOcbTFEiPBKA","colab_type":"text"},"source":["## Downloading and Orgniazing Images and Annotations\n","1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n","2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n","3. Creating two directories; for the training and testing labels (not the images)\n","4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "]},{"cell_type":"code","metadata":{"id":"2QY-CyUQwyZr","colab_type":"code","colab":{}},"source":["#creates a directory for the whole project\n","!mkdir gun_detection"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHPQQmhm7RLe","colab_type":"code","outputId":"51462ecc-7297-46de-fe7f-9cb458d68a26","executionInfo":{"status":"ok","timestamp":1589969005234,"user_tz":-120,"elapsed":25329,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd gun_detection"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/gun_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A30JtScTB1ny","colab_type":"code","outputId":"170e1aa6-91a0-44f7-c795-a1dfbd6a8258","executionInfo":{"status":"ok","timestamp":1589969025062,"user_tz":-120,"elapsed":45133,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":75}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-e040bbf3-e901-4493-b965-e35df5e33d9b\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-e040bbf3-e901-4493-b965-e35df5e33d9b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving images.zip to images.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kyCcmoJRCHBe","colab_type":"code","colab":{}},"source":["!unzip -q images.zip #WeaponS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9iw2seZEP5P","colab_type":"code","outputId":"43ed215f-4b56-4432-8d66-9d105d61b59e","executionInfo":{"status":"ok","timestamp":1589969032258,"user_tz":-120,"elapsed":52297,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":75}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ad68ea9a-19da-4fff-ac25-85837ed4bf6c\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ad68ea9a-19da-4fff-ac25-85837ed4bf6c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving annotations.zip to annotations.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nk4nAMHzEWoJ","colab_type":"code","colab":{}},"source":["!unzip -q annotations.zip  #WeaponS_bbox"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9ULYGRRFb-K","colab_type":"code","colab":{}},"source":["# creating a directory to store the training and testing data\n","!mkdir data\n","\n","# folders for the training and testing data.\n","!mkdir data/images data/train_labels data/test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0czMMeR8GxW","colab_type":"code","colab":{}},"source":["# combining the images and annotation in the training folder:\n","# moves the images to data folder\n","!mv images/* data/images\n","\n","# moves the annotations to data folder\n","!mv annotations/* data/train_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vv8pmB2D80M7","colab_type":"code","colab":{}},"source":["# Deleting the zipped and unzipped folders \n","!rm -rf annotations.zip  images.zip images/  annotations/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUl-XRwPvj4j","colab_type":"code","colab":{}},"source":["\n","# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n","# Moves the first 600 labels to the testing dir: `test_labels`\n","!ls data/train_labels/* | sort -R | head -31 | xargs -I{} mv {} data/test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmvDu-rUHz96","colab_type":"code","outputId":"59cebfdf-9dd2-4ac8-c7b7-a2c0bad72a1c","executionInfo":{"status":"ok","timestamp":1589969041562,"user_tz":-120,"elapsed":61508,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 2400 \"images\"(xml) for training\n","!ls -1 data/train_labels/ | wc -l"],"execution_count":17,"outputs":[{"output_type":"stream","text":["122\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K8y-1_t7wRJc","colab_type":"code","outputId":"69165fb5-d4a3-4f0f-f049-3fd446284232","executionInfo":{"status":"ok","timestamp":1589969043232,"user_tz":-120,"elapsed":63143,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 600 \"images\"(xml) for testing\n","!ls -1 data/test_labels/ | wc -l"],"execution_count":18,"outputs":[{"output_type":"stream","text":["31\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pOfuwfPrPSMz","colab_type":"text"},"source":["## Preprocessing Images and Labels\n","1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n","2. Creating a pbtxt file that specifies the number of class (one class in this case)\n","3. Checking if the annotations for each object are placed within the range of the image width and height."]},{"cell_type":"code","metadata":{"id":"TBHBFpWyEIDI","colab_type":"code","outputId":"3d06e2fe-0519-475e-fcb9-8717bcb61019","executionInfo":{"status":"ok","timestamp":1589969043242,"user_tz":-120,"elapsed":63123,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["\n","#adjusted from: https://github.com/datitran/raccoon_dataset\n","\n","#converts the annotations/labels into one csv file for each training and testing labels\n","#creats label_map.pbtxt file\n","\n","%cd /content/gun_detection/data\n","\n","\n","# images extension\n","images_extension = ''\n","\n","# takes the path of a directory that contains xml files and converts\n","#  them to one csv file.\n","\n","# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n","# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text + '' + images_extension,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name) \n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","# Creating the `label_map.pbtxt` file\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","\n","pbtxt_content = \"\"\n","\n","#creats a pbtxt file the has the class names.\n","for i, class_name in enumerate(classes):\n","    # display_name is optional.\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'bottle'\\n }}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/content/gun_detection/data\n","Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtfjZcD-CCdM","colab_type":"code","outputId":"9398f6ed-960f-403f-d41d-37c93316a633","executionInfo":{"status":"ok","timestamp":1589969044773,"user_tz":-120,"elapsed":64571,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["#checking the pbtxt file\n","!cat label_map.pbtxt"],"execution_count":20,"outputs":[{"output_type":"stream","text":["item {\n","    id: 1\n","    name: 'bottle'\n","    display_name: 'bottle'\n"," }"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yP8gohagKFXn","colab_type":"code","outputId":"7038546f-8be7-44aa-efa2-d5e2c5d2e502","executionInfo":{"status":"ok","timestamp":1589969046132,"user_tz":-120,"elapsed":65897,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# they are there!\n","!ls -l"],"execution_count":21,"outputs":[{"output_type":"stream","text":["total 28\n","drwxr-xr-x 2 root root 4096 May 20 10:03 images\n","-rw-r--r-- 1 root root   65 May 20 10:04 label_map.pbtxt\n","drwxr-xr-x 2 root root 4096 May 20 10:03 test_labels\n","-rw-r--r-- 1 root root 1886 May 20 10:04 test_labels.csv\n","drwxr-xr-x 2 root root 4096 May 20 10:03 train_labels\n","-rw-r--r-- 1 root root 7137 May 20 10:04 train_labels.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L4p7J6mFLLZf","colab_type":"code","outputId":"d3c5d49d-a503-40d8-85e5-9c0b81bb4273","executionInfo":{"status":"ok","timestamp":1589969046498,"user_tz":-120,"elapsed":66241,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["#checks if the images box position is placed within the image.\n","\n","#note: while this doesn't checks if the boxes/annotatoins are correctly\n","# placed around the object, Tensorflow will through an error if this occured.\n","%cd /content/gun_detection/data\n","# path to images\n","images_path = 'images'\n","\n","#loops over both train_labels and test_labels csv files to do the check\n","# returns the image name where an error is found \n","# return the incorrect attributes; xmin, ymin, xmax, ymax.\n","for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n","  with open(CSV_FILE, 'r') as fid:  \n","      print('[*] Checking file:', CSV_FILE) \n","      file = csv.reader(fid, delimiter=',')\n","      first = True \n","      cnt = 0\n","      error_cnt = 0\n","      error = False\n","      for row in file:\n","          if error == True:\n","              error_cnt += 1\n","              error = False         \n","          if first == True:\n","              first = False\n","              continue     \n","          cnt += 1      \n","          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n","          path = os.path.join(images_path, name)\n","          img = cv2.imread(path)         \n","          if type(img) == type(None):\n","              error = True\n","              print('Could not read image', img)\n","              continue     \n","          org_height, org_width = img.shape[:2]     \n","          if org_width != width:\n","              error = True\n","              print('Width mismatch for image: ', name, width, '!=', org_width)     \n","          if org_height != height:\n","              error = True\n","              print('Height mismatch for image: ', name, height, '!=', org_height) \n","          if xmin > org_width:\n","              error = True\n","              print('XMIN > org_width for file', name)  \n","          if xmax > org_width:\n","              error = True\n","              print('XMAX > org_width for file', name)\n","          if ymin > org_height:\n","              error = True\n","              print('YMIN > org_height for file', name)\n","          if ymax > org_height:\n","              error = True\n","              print('YMAX > org_height for file', name)\n","          if error == True:\n","              print('Error for file: %s' % name)\n","              print()\n","      print()\n","      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n","      print(\"-----\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/content/gun_detection/data\n","[*] Checking file: train_labels.csv\n","\n","Checked 158 files and realized 0 errors\n","-----\n","[*] Checking file: test_labels.csv\n","\n","Checked 41 files and realized 0 errors\n","-----\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vD5luKTsMx7F","colab_type":"code","outputId":"5fe8bd22-e82b-40cc-9644-84ca26e0a7a3","executionInfo":{"status":"error","timestamp":1589969046819,"user_tz":-120,"elapsed":66532,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":131}},"source":["#we have only one image with incorrect box position, we could just remove it \n","#removing the image \n","rm images/'armas (2815).jpg'"],"execution_count":23,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-501f3c664a23>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    rm images/'armas (2815).jpg'\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"ze4z9bW3ZjhC","colab_type":"code","colab":{}},"source":["#removing the entry for it in the csv for that image as well\n","\n","#because we did a random split for the data, we dont know if it ended up being in training or testing\n","# we will remove the image from both.\n","\n","#training\n","#reading the training csv\n","df = pd.read_csv('/content/gun_detection/data/train_labels.csv')\n","# removing armas (2815).jpg\n","df = df[df['filename'] != 'armas (2815).jpg']\n","#reseting the index\n","df.reset_index(drop=True, inplace=True)\n","#saving the df\n","df.to_csv('/content/gun_detection/data/train_labels.csv')\n","\n","\n","#testing\n","#reading the testing csv\n","df = pd.read_csv('/content/gun_detection/data/test_labels.csv')\n","# removing armas (2815).jpg\n","df = df[df['filename'] != 'armas (2815).jpg']\n","#reseting the index\n","df.reset_index(drop=True, inplace=True)\n","#saving the df\n","df.to_csv('/content/gun_detection/data/test_labels.csv')\n","\n","# Just for the memory\n","df = None\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A_tyvKnBP6qD","colab_type":"text"},"source":["## Downloading and Preparing Tensorflow model\n","1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n","2. Compiling the protos and adding folders to the os environment.\n","3. Testing the model builder."]},{"cell_type":"code","metadata":{"id":"IIxz1GqJQA3f","colab_type":"code","outputId":"e1dcf3c8-ed34-4eb5-cc8b-d0c07b2eb825","executionInfo":{"status":"ok","timestamp":1589969084831,"user_tz":-120,"elapsed":24235,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Downlaods Tenorflow\n","%cd /content/gun_detection/\n","!git clone --q https://github.com/tensorflow/models.git"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/content/gun_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tjcAhsxRQ5N1","colab_type":"code","outputId":"86d88454-6324-4dd1-86ce-e7ae81617247","executionInfo":{"status":"ok","timestamp":1589969085879,"user_tz":-120,"elapsed":25262,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%cd /content/gun_detection/models/research\n","#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n","os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research\n","object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3bMNsrwTSJi2","colab_type":"code","colab":{}},"source":["# testing the model builder\n","!python3 object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9C3L_r4Pi6m","colab_type":"text"},"source":["## Generating Tf record\n","- Generating two TFRecords files for the training and testing CSVs.\n","- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"]},{"cell_type":"code","metadata":{"id":"nK2unk-9LB_E","colab_type":"code","outputId":"d5e5905d-12bc-4002-f0f9-c54fa1ec52d3","executionInfo":{"status":"ok","timestamp":1589969091200,"user_tz":-120,"elapsed":30548,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#adjusted from: https://github.com/datitran/raccoon_dataset\n","\n","# converts the csv files for training and testing data to two TFRecords files.\n","# places the output in the same directory as the input\n","\n","\n","from object_detection.utils import dataset_util\n","%cd /content/gun_detection/models/\n","\n","DATA_BASE_PATH = '/content/gun_detection/data/'\n","image_dir = DATA_BASE_PATH +'images/'\n","\n","def class_text_to_int(row_label):\n","\t\tif row_label == 'bottle':\n","\t\t\t\treturn 1\n","\t\telse:\n","\t\t\t\tNone\n","\n","\n","def split(df, group):\n","\t\tdata = namedtuple('data', ['filename', 'object'])\n","\t\tgb = df.groupby(group)\n","\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n","\n","def create_tf_example(group, path):\n","\t\twith tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n","\t\t\t\tencoded_jpg = fid.read()\n","\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n","\t\timage = Image.open(encoded_jpg_io)\n","\t\twidth, height = image.size\n","\n","\t\tfilename = group.filename.encode('utf8')\n","\t\timage_format = b'jpg'\n","\t\txmins = []\n","\t\txmaxs = []\n","\t\tymins = []\n","\t\tymaxs = []\n","\t\tclasses_text = []\n","\t\tclasses = []\n","\n","\t\tfor index, row in group.object.iterrows():\n","\t\t\t\txmins.append(row['xmin'] / width)\n","\t\t\t\txmaxs.append(row['xmax'] / width)\n","\t\t\t\tymins.append(row['ymin'] / height)\n","\t\t\t\tymaxs.append(row['ymax'] / height)\n","\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n","\t\t\t\tclasses.append(class_text_to_int(row['class']))\n","\n","\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n","\t\t\t\t'image/height': dataset_util.int64_feature(height),\n","\t\t\t\t'image/width': dataset_util.int64_feature(width),\n","\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n","\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n","\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n","\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n","\t\t}))\n","\t\treturn tf_example\n","\n","for csv in ['train_labels', 'test_labels']:\n","  writer = tf.python_io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n","  path = os.path.join(image_dir)\n","  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n","  grouped = split(examples, 'filename')\n","  for group in grouped:\n","      tf_example = create_tf_example(group, path)\n","      writer.write(tf_example.SerializeToString())\n","    \n","  writer.close()\n","  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n","  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models\n","Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n","Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i1zRJducWs-X","colab_type":"code","outputId":"2c2da6a4-b291-4839-dbbf-db587e5e00c9","executionInfo":{"status":"ok","timestamp":1589969092432,"user_tz":-120,"elapsed":31766,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# TFRecords are created\n","!ls -lX /content/gun_detection/data/"],"execution_count":28,"outputs":[{"output_type":"stream","text":["total 720\n","drwxr-xr-x 2 root root   4096 May 20 10:03 images\n","drwxr-xr-x 2 root root   4096 May 20 10:03 test_labels\n","drwxr-xr-x 2 root root   4096 May 20 10:03 train_labels\n","-rw-r--r-- 1 root root   1886 May 20 10:04 test_labels.csv\n","-rw-r--r-- 1 root root   7137 May 20 10:04 train_labels.csv\n","-rw-r--r-- 1 root root     65 May 20 10:04 label_map.pbtxt\n","-rw-r--r-- 1 root root 154518 May 20 10:04 test_labels.record\n","-rw-r--r-- 1 root root 551975 May 20 10:04 train_labels.record\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xMckMSJqFMyc","colab_type":"text"},"source":["## Downloading the Base Model\n","1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n","2. Creating a dir to save the model while training."]},{"cell_type":"code","metadata":{"id":"UvN9Cw65FQzB","colab_type":"code","outputId":"e1abfe5a-4ac5-4052-84da-1905f2dd897a","executionInfo":{"status":"ok","timestamp":1589969095790,"user_tz":-120,"elapsed":35099,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/gun_detection/models/research\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#the distination folder where the model will be saved\n","fine_tune_dir = '/content/gun_detection/models/research/pretrained_model'\n","\n","#checks if the model has already been downloaded\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the file and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(fine_tune_dir)):\n","    shutil.rmtree(fine_tune_dir)\n","os.rename(MODEL, fine_tune_dir)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pbjXKVMmFk47","colab_type":"code","outputId":"177d078d-32fc-4c9c-b98c-bf092075d01a","executionInfo":{"status":"ok","timestamp":1589969097981,"user_tz":-120,"elapsed":37276,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#checking the content of the pretrained model.\n","# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n","!echo {fine_tune_dir}\n","!ls -alh {fine_tune_dir}"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/content/gun_detection/models/research/pretrained_model\n","total 135M\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n","drwxr-xr-x 63 root   root  4.0K May 20 10:04 ..\n","-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n","-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n","-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HnjQgJZiGAcA","colab_type":"text"},"source":["## Configuring the Training Pipeline\n","1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n","2. Adding some Image augmentation.\n","3. Creating a directory to save the model at each checkpoint while training. "]},{"cell_type":"code","metadata":{"id":"az14XVo31Ujp","colab_type":"code","outputId":"2cfc2563-0fd1-4c45-8b67-76609beafdda","executionInfo":{"status":"ok","timestamp":1589969097986,"user_tz":-120,"elapsed":37268,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","#the path to the folder containing all the sample config files\n","CONFIG_BASE = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n","\n","#path to the specified model's config file\n","model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n","model_pipline"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"VT3m6pbXpN_M","colab_type":"code","colab":{}},"source":["#check the sample config file that is provided by the tf model\n","#!cat /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kfsl5CsDGY3-","colab_type":"code","outputId":"059cc34d-0b26-4877-90d3-9c54bd04ebb1","executionInfo":{"status":"ok","timestamp":1589969097990,"user_tz":-120,"elapsed":37242,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n","# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n","\n","%%writefile {model_pipline}\n","model {\n","  ssd {\n","    num_classes: 1 # number of classes to be detected\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    # all images will be resized to the below W x H.\n","    image_resizer { \n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        #use_dropout: false\n","        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000 \n","        iou_threshold: 0.95\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        \n","        #adjust this to the max number of objects per class. \n","        # ex, in my case, i have one pistol in most of the images.\n","        # . there are some images with more than one up to 16.\n","        max_detections_per_class: 16\n","        # max number of detections among all classes. I have 1 class only so\n","        max_total_detections: 16\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 16 # training batch size\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.003\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","\n","  #the path to the pretrained model. \n","  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000 \n","  \n","\n","  #data augmentaion is done here, you can remove or add more.\n","  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n","  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n","  \n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_contrast {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    #path to the training TFRecord\n","    input_path: \"/content/gun_detection/data/train_labels.record\"\n","  }\n","  #path to the label map \n","  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n","  num_examples: 599\n","  # the number of images to disply in Tensorboard while training\n","  num_visualizations: 20\n","\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  #max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","      \n","    #path to the testing TFRecord\n","    input_path: \"/content/gun_detection/data/test_labels.record\"\n","  }\n","  #path to the label map \n","  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EuXXZLVEG8sO","colab_type":"code","colab":{}},"source":["# where the model will be saved at each checkpoint while training \n","model_dir = 'training/'\n","\n","# Optionally: remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vAGvftxHu8K","colab_type":"text"},"source":["## Tensorboard\n","1. Downlaoding and unzipping Tensorboard\n","2. creating a link to visualize multiple graph while training.\n","\n","\n","notes: \n","  1. Tensorboard will not log any files until the training starts. \n","  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."]},{"cell_type":"code","metadata":{"id":"Z2ucxlc5HxHL","colab_type":"code","outputId":"65cfc3c6-5737-4513-d012-5da8610e211b","executionInfo":{"status":"ok","timestamp":1589969102300,"user_tz":-120,"elapsed":41493,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["#downlaoding ngrok to be able to access tensorboard on google colab\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":35,"outputs":[{"output_type":"stream","text":["--2020-05-20 10:04:59--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.193.189.199, 3.224.101.150, 3.215.12.181, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.193.189.199|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  37.2MB/s    in 0.4s    \n","\n","2020-05-20 10:05:00 (37.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-w9ufxr7IAdv","colab_type":"code","colab":{}},"source":["#the logs that are created while training \n","LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")\n","get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"idsi9zyNIIsr","colab_type":"code","outputId":"da6e0f8f-7dfc-46ab-9759-83b51e8e6588","executionInfo":{"status":"ok","timestamp":1589969103707,"user_tz":-120,"elapsed":42857,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#The link to tensorboard.\n","#works after the training starts.\n","\n","### note: if you didnt get a link as output, rerun this cell and the one above\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":37,"outputs":[{"output_type":"stream","text":["http://7d52bb8e.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IuJcAPZFIfu7","colab_type":"text"},"source":["## Training\n","\n","Finally training the model!\n"]},{"cell_type":"code","metadata":{"id":"vnKt6g0_IgOe","colab_type":"code","outputId":"ac9b7d9a-7ad5-4bd2-996a-b18b5eabe026","executionInfo":{"status":"ok","timestamp":1589969799976,"user_tz":-120,"elapsed":739114,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={model_pipline}\\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\"],"execution_count":38,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0520 10:05:08.831642 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0520 10:05:08.835884 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0520 10:05:08.836089 140254443251584 model_lib.py:686] Forced number of epochs for all eval validations to be 1.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0520 10:05:08.836287 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0520 10:05:08.836439 140254443251584 config_util.py:523] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0520 10:05:08.836595 140254443251584 config_util.py:523] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0520 10:05:08.836757 140254443251584 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0520 10:05:08.836973 140254443251584 config_util.py:523] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0520 10:05:08.837129 140254443251584 config_util.py:523] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0520 10:05:08.837279 140254443251584 config_util.py:533] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0520 10:05:08.838231 140254443251584 model_lib.py:702] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0520 10:05:08.838425 140254443251584 model_lib.py:737] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8f29c44d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0520 10:05:08.838968 140254443251584 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8f29c44d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f8f0fa8f0d0>) includes params argument, but params are not passed to Estimator.\n","W0520 10:05:08.839248 140254443251584 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f8f0fa8f0d0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0520 10:05:08.840033 140254443251584 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0520 10:05:08.840281 140254443251584 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0520 10:05:08.840587 140254443251584 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0520 10:05:08.846889 140254443251584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:208: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0520 10:05:08.860455 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:208: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:223: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0520 10:05:08.860814 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/data_decoders/tf_example_decoder.py:223: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:76: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0520 10:05:08.875590 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:76: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0520 10:05:08.877111 140254443251584 dataset_builder.py:84] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0520 10:05:08.884574 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0520 10:05:08.884841 140254443251584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:182: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0520 10:05:08.912798 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:182: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","W0520 10:05:10.610780 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0520 10:05:20.286303 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/ops.py:500: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0520 10:05:20.381179 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/ops.py:500: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0520 10:05:23.068775 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0520 10:05:27.653461 140254443251584 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0520 10:05:31.740999 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0520 10:05:31.743544 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:244: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0520 10:05:32.247033 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:244: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","W0520 10:05:35.328659 140254443251584 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:185: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W0520 10:05:36.088428 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:185: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","INFO:tensorflow:Calling model_fn.\n","I0520 10:05:36.105432 140254443251584 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0520 10:05:36.524578 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0520 10:05:36.524966 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0520 10:05:36.529279 140254443251584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0520 10:05:39.780661 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:39.794052 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:39.843498 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:39.892118 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:39.946426 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:39.996764 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:05:40.058747 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:178: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0520 10:05:40.114127 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:178: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:138: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0520 10:05:40.115329 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/variables_helper.py:138: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0520 10:05:40.119776 140254443251584 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n","W0520 10:05:40.120007 140254443251584 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0520 10:05:40.120229 140254443251584 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0520 10:05:40.120409 140254443251584 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:402: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0520 10:05:40.120625 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:402: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0520 10:05:41.430035 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0520 10:05:44.379257 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/losses.py:178: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0520 10:05:44.386199 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/core/losses.py:178: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/losses.py:184: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0520 10:05:44.387574 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/core/losses.py:184: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","W0520 10:05:44.854521 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:434: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0520 10:05:44.857564 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:434: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","W0520 10:05:44.857898 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/optimizer_builder.py:48: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","W0520 10:05:44.868797 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/builders/optimizer_builder.py:48: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:451: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0520 10:05:44.869119 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:451: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0520 10:05:47.399011 140254443251584 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:572: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0520 10:05:54.421100 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:572: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:576: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0520 10:05:55.325903 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:576: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:577: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0520 10:05:55.326274 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:577: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0520 10:05:55.326870 140254443251584 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0520 10:05:55.328688 140254443251584 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0520 10:05:59.867591 140254443251584 monitored_session.py:240] Graph was finalized.\n","2020-05-20 10:05:59.868157: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-05-20 10:05:59.873356: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-05-20 10:05:59.873627: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a1cf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-05-20 10:05:59.873662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-05-20 10:05:59.877843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-05-20 10:06:00.014088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:00.014985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a1cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-05-20 10:06:00.015022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-05-20 10:06:00.016439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:00.017165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:06:00.034924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:06:00.213207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:06:00.305809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:06:00.333970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:06:00.582340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:06:00.712080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:06:01.217442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:06:01.217715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:01.218615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:01.219318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:06:01.219443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:06:01.221205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-20 10:06:01.221245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-20 10:06:01.221270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-20 10:06:01.221465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:01.222300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:06:01.223062: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-05-20 10:06:01.223121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Running local_init_op.\n","I0520 10:06:06.939879 140254443251584 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 10:06:07.363257 140254443251584 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n","I0520 10:06:19.490191 140254443251584 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","2020-05-20 10:06:30.210552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:06:34.266486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","INFO:tensorflow:loss = 13.088933, step = 0\n","I0520 10:06:37.771153 140254443251584 basic_session_run_hooks.py:262] loss = 13.088933, step = 0\n","INFO:tensorflow:global_step/sec: 1.7211\n","I0520 10:07:35.872490 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.7211\n","INFO:tensorflow:loss = 5.261468, step = 100 (58.103 sec)\n","I0520 10:07:35.873894 140254443251584 basic_session_run_hooks.py:260] loss = 5.261468, step = 100 (58.103 sec)\n","INFO:tensorflow:global_step/sec: 1.91065\n","I0520 10:08:28.210664 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.91065\n","INFO:tensorflow:loss = 3.1918619, step = 200 (52.338 sec)\n","I0520 10:08:28.212059 140254443251584 basic_session_run_hooks.py:260] loss = 3.1918619, step = 200 (52.338 sec)\n","INFO:tensorflow:global_step/sec: 1.89758\n","I0520 10:09:20.909198 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.89758\n","INFO:tensorflow:loss = 3.6281128, step = 300 (52.698 sec)\n","I0520 10:09:20.910429 140254443251584 basic_session_run_hooks.py:260] loss = 3.6281128, step = 300 (52.698 sec)\n","INFO:tensorflow:global_step/sec: 1.90125\n","I0520 10:10:13.506256 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.90125\n","INFO:tensorflow:loss = 3.0720992, step = 400 (52.598 sec)\n","I0520 10:10:13.508472 140254443251584 basic_session_run_hooks.py:260] loss = 3.0720992, step = 400 (52.598 sec)\n","INFO:tensorflow:global_step/sec: 1.88952\n","I0520 10:11:06.429901 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.88952\n","INFO:tensorflow:loss = 3.4313776, step = 500 (52.923 sec)\n","I0520 10:11:06.431231 140254443251584 basic_session_run_hooks.py:260] loss = 3.4313776, step = 500 (52.923 sec)\n","INFO:tensorflow:global_step/sec: 1.8846\n","I0520 10:11:59.491478 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.8846\n","INFO:tensorflow:loss = 2.4221754, step = 600 (53.062 sec)\n","I0520 10:11:59.492816 140254443251584 basic_session_run_hooks.py:260] loss = 2.4221754, step = 600 (53.062 sec)\n","INFO:tensorflow:global_step/sec: 1.90741\n","I0520 10:12:51.918703 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.90741\n","INFO:tensorflow:loss = 3.3388176, step = 700 (52.427 sec)\n","I0520 10:12:51.919848 140254443251584 basic_session_run_hooks.py:260] loss = 3.3388176, step = 700 (52.427 sec)\n","INFO:tensorflow:global_step/sec: 1.94314\n","I0520 10:13:43.381908 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.94314\n","INFO:tensorflow:loss = 2.267663, step = 800 (51.464 sec)\n","I0520 10:13:43.383396 140254443251584 basic_session_run_hooks.py:260] loss = 2.267663, step = 800 (51.464 sec)\n","INFO:tensorflow:global_step/sec: 1.94405\n","I0520 10:14:34.821062 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.94405\n","INFO:tensorflow:loss = 2.2126622, step = 900 (51.439 sec)\n","I0520 10:14:34.822464 140254443251584 basic_session_run_hooks.py:260] loss = 2.2126622, step = 900 (51.439 sec)\n","INFO:tensorflow:global_step/sec: 1.89818\n","I0520 10:15:27.503162 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.89818\n","INFO:tensorflow:loss = 2.3687594, step = 1000 (52.682 sec)\n","I0520 10:15:27.504598 140254443251584 basic_session_run_hooks.py:260] loss = 2.3687594, step = 1000 (52.682 sec)\n","INFO:tensorflow:global_step/sec: 1.89069\n","I0520 10:16:20.393998 140254443251584 basic_session_run_hooks.py:692] global_step/sec: 1.89069\n","INFO:tensorflow:loss = 2.1420736, step = 1100 (52.891 sec)\n","I0520 10:16:20.395566 140254443251584 basic_session_run_hooks.py:260] loss = 2.1420736, step = 1100 (52.891 sec)\n","INFO:tensorflow:Saving checkpoints for 1105 into training/model.ckpt.\n","I0520 10:16:22.493537 140254443251584 basic_session_run_hooks.py:606] Saving checkpoints for 1105 into training/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0520 10:16:25.646780 140254443251584 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.445926 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.486690 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.525800 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.570156 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.614377 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:28.653733 140254443251584 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/eval_util.py:819: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0520 10:16:29.512341 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/eval_util.py:819: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0520 10:16:29.766926 140254443251584 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:1293: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0520 10:16:29.962958 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:1293: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/model_lib.py:541: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0520 10:16:30.165429 140254443251584 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/model_lib.py:541: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0520 10:16:30.549572 140254443251584 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-05-20T10:16:30Z\n","I0520 10:16:30.570857 140254443251584 evaluation.py:255] Starting evaluation at 2020-05-20T10:16:30Z\n","INFO:tensorflow:Graph was finalized.\n","I0520 10:16:31.142516 140254443251584 monitored_session.py:240] Graph was finalized.\n","2020-05-20 10:16:31.143767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:31.144398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:16:31.144534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:31.144588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:16:31.144670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:16:31.144740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:16:31.144875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:16:31.144951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:16:31.145012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:16:31.145168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:31.145814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:31.146382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:16:31.146443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-20 10:16:31.146471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-20 10:16:31.146500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-20 10:16:31.146666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:31.147310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:31.147860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1105\n","I0520 10:16:31.149329 140254443251584 saver.py:1284] Restoring parameters from training/model.ckpt-1105\n","INFO:tensorflow:Running local_init_op.\n","I0520 10:16:32.165890 140254443251584 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0520 10:16:32.311235 140254443251584 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 31 images.\n","I0520 10:16:36.404674 140252180702976 coco_evaluation.py:236] Performing evaluation on 31 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0520 10:16:36.405334 140252180702976 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0520 10:16:36.406291 140252180702976 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","2020-05-20 10:16:36.419240: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n","    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n","  (0) Out of range: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\t [[IteratorGetNext/_2015]]\n","  (1) Out of range: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n","    session.run(eval_ops, feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n","    raise six.reraise(*original_exc_info)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n","  (0) Out of range: End of sequence\n","\t [[node IteratorGetNext (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[IteratorGetNext/_2015]]\n","  (1) Out of range: End of sequence\n","\t [[node IteratorGetNext (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'IteratorGetNext':\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n","    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n","    self._call_model_fn_eval(input_fn, self.config))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _call_model_fn_eval\n","    input_fn, ModeKeys.EVAL)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n","    self._call_input_fn(input_fn, mode))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n","    result = iterator.get_next()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n","    output_shapes=output_shapes, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n","  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n","    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[{{node PyFunc_3}}]]\n","\t [[cond_6/Const/_2581]]\n","  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n","    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[{{node PyFunc_3}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n","    raise six.reraise(*original_exc_info)\n","  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n","    raise value\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\n","    output_dir=self.eval_dir(name))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\n","    config=self._session_config)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n","    session.run(eval_ops, feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 861, in __exit__\n","    self._close_internal(exception_type)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 894, in _close_internal\n","    h.end(self._coordinated_creator.tf_sess)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 951, in end\n","    self._final_ops, feed_dict=self._final_ops_feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n","  (0) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n","    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[node PyFunc_3 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[cond_6/Const/_2581]]\n","  (1) Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 117, in linspace\n","    num = operator.index(num)\n","\n","TypeError: 'numpy.float64' object cannot be interpreted as an integer\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","Traceback (most recent call last):\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n","    ret = func(*args)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\n","    self._metrics = self.evaluate()\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\n","    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n","\n","  File \"/content/gun_detection/models/research/object_detection/metrics/coco_tools.py\", line 177, in __init__\n","    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 76, in __init__\n","    self.params = Params(iouType=iouType) # parameters\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 527, in __init__\n","    self.setDetParams()\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n","    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n","\n","  File \"<__array_function__ internals>\", line 6, in linspace\n","\n","  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/function_base.py\", line 121, in linspace\n","    .format(type(num)))\n","\n","TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n","\n","\n","\t [[node PyFunc_3 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'PyFunc_3':\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 109, in <module>\n","    tf.app.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/gun_detection/models/research/object_detection/model_main.py\", line 105, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n","    return executor.run()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n","    return self.run_local()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n","    saving_listeners)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n","    run_metadata=run_metadata)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n","    run_metadata=run_metadata))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n","    if self._save(run_context.session, global_step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n","    if l.after_save(session, step):\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n","    self._evaluate(global_step_value)  # updates self.eval_result\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n","    self._evaluator.evaluate_and_export())\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n","    hooks=self._eval_spec.hooks)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n","    name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n","    return _evaluate()\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n","    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n","    self._call_model_fn_eval(input_fn, self.config))\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1547, in _call_model_fn_eval\n","    features, labels, ModeKeys.EVAL, config)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n","    model_fn_results = self._model_fn(features=features, **kwargs)\n","  File \"content/gun_detection/models/research/object_detection/model_lib.py\", line 539, in model_fn\n","    eval_config, list(category_index.values()), eval_dict)\n","  File \"content/gun_detection/models/research/object_detection/eval_util.py\", line 1034, in get_eval_metric_ops_for_evaluators\n","    eval_dict))\n","  File \"content/gun_detection/models/research/object_detection/metrics/coco_evaluation.py\", line 425, in get_estimator_eval_metric_ops\n","    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 513, in py_func\n","    return py_func_common(func, inp, Tout, stateful, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 495, in py_func_common\n","    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py\", line 318, in _internal_py_func\n","    input=inp, token=token, Tout=Tout, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 170, in py_func\n","    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RPN8liiQc7Ue","colab_type":"text"},"source":["## Exporting The Trained model\n","\n"]},{"cell_type":"code","metadata":{"id":"upwUdom0lTub","colab_type":"code","outputId":"3284ffc6-4a4b-45e7-9baa-14f7e71632bf","executionInfo":{"status":"ok","timestamp":1589969816778,"user_tz":-120,"elapsed":755900,"user":{"displayName":"akileswaran karthikeyan","photoUrl":"","userId":"16001558852903191333"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","#the location where the exported model will be saved in.\n","output_directory = '/content/gun_detection/models/research/fine_tuned_model'\n","\n","# goes through the model is the training/ dir and gets the last one.\n","# you could choose a specfic one instead of the last\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","\n","#exports the model specifed and inference graph\n","!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={model_pipline} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":39,"outputs":[{"output_type":"stream","text":["training/model.ckpt-1105\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0520 10:16:43.970296 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0520 10:16:43.978090 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:419: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0520 10:16:43.978480 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:138: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0520 10:16:44.020051 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/core/preprocessor.py:3030: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0520 10:16:44.053605 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:600: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0520 10:16:44.053959 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/meta_architectures/ssd_meta_arch.py:608: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0520 10:16:44.057263 139984383674240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0520 10:16:46.847035 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0520 10:16:46.861877 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/predictors/convolutional_box_predictor.py:157: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:46.862150 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:46.913381 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:46.963761 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:47.147521 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:47.202085 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0520 10:16:47.253006 139984383674240 convolutional_box_predictor.py:158] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0520 10:16:47.602173 139984383674240 deprecation.py:323] From /content/gun_detection/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0520 10:16:48.027429 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:295: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0520 10:16:48.027757 139984383674240 deprecation.py:323] From /content/gun_detection/models/research/object_detection/exporter.py:400: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0520 10:16:48.032238 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:432: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0520 10:16:48.032466 139984383674240 deprecation.py:323] From /content/gun_detection/models/research/object_detection/exporter.py:555: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0520 10:16:48.034115 139984383674240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","133 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.57m params)\n","  BoxPredictor_0 (--/10.39k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/3.46k params)\n","      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n","  BoxPredictor_1 (--/46.12k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/15.37k params)\n","      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n","  BoxPredictor_2 (--/18.47k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/6.16k params)\n","      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","  BoxPredictor_3 (--/9.25k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/3.08k params)\n","      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_4 (--/9.25k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/3.08k params)\n","      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n","  BoxPredictor_5 (--/4.64k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/1.55k params)\n","      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","133 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.71k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0520 10:16:49.393886 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:449: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0520 10:16:50.566125 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:359: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-05-20 10:16:50.567681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-05-20 10:16:50.585281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.586104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:16:50.586436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:50.587773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:16:50.600252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:16:50.600629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:16:50.602231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:16:50.612873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:16:50.625062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:16:50.625235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.626072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.626761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:16:50.627210: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-05-20 10:16:50.633084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-05-20 10:16:50.633407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d1ed80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-05-20 10:16:50.633447: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-05-20 10:16:50.687030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.687878: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d1ef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-05-20 10:16:50.687919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-05-20 10:16:50.688177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.688866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:16:50.688981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:50.689044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:16:50.689101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:16:50.689153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:16:50.689202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:16:50.689259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:16:50.689310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:16:50.689451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.690317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.691087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:16:50.691179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:50.692803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-20 10:16:50.692839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-20 10:16:50.692869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-20 10:16:50.693093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.694111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:50.694825: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-05-20 10:16:50.694897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1105\n","I0520 10:16:50.697356 139984383674240 saver.py:1284] Restoring parameters from training/model.ckpt-1105\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0520 10:16:52.414138 139984383674240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-05-20 10:16:53.145011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:53.145758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:16:53.145874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:53.145961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:16:53.146028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:16:53.146086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:16:53.146140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:16:53.146197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:16:53.146253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:16:53.146414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:53.147243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:53.147962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:16:53.148050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-20 10:16:53.148079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-20 10:16:53.148108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-20 10:16:53.148282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:53.149108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:53.149794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-1105\n","I0520 10:16:53.151213 139984383674240 saver.py:1284] Restoring parameters from training/model.ckpt-1105\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0520 10:16:53.835304 139984383674240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0520 10:16:53.835656 139984383674240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0520 10:16:54.238551 139984383674240 graph_util_impl.py:334] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0520 10:16:54.346201 139984383674240 graph_util_impl.py:394] Converted 324 variables to const ops.\n","2020-05-20 10:16:54.493467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:54.494359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-05-20 10:16:54.494470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-05-20 10:16:54.494534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-05-20 10:16:54.494592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-05-20 10:16:54.494657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-05-20 10:16:54.494716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-05-20 10:16:54.494766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-05-20 10:16:54.494827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-05-20 10:16:54.495052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:54.495920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:54.496617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-05-20 10:16:54.496673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-05-20 10:16:54.496701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-05-20 10:16:54.496719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-05-20 10:16:54.496887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:54.497760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-05-20 10:16:54.498598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0520 10:16:55.169801 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:323: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0520 10:16:55.170359 139984383674240 deprecation.py:323] From /content/gun_detection/models/research/object_detection/exporter.py:326: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0520 10:16:55.170899 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:332: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0520 10:16:55.171185 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:335: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0520 10:16:55.171491 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:340: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","W0520 10:16:55.171706 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/exporter.py:342: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","INFO:tensorflow:No assets to save.\n","I0520 10:16:55.172090 139984383674240 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0520 10:16:55.172244 139984383674240 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/gun_detection/models/research/fine_tuned_model/saved_model/saved_model.pb\n","I0520 10:16:55.510505 139984383674240 builder_impl.py:425] SavedModel written to: /content/gun_detection/models/research/fine_tuned_model/saved_model/saved_model.pb\n","WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0520 10:16:55.538374 139984383674240 module_wrapper.py:139] From /content/gun_detection/models/research/object_detection/utils/config_util.py:223: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","INFO:tensorflow:Writing pipeline config file to /content/gun_detection/models/research/fine_tuned_model/pipeline.config\n","I0520 10:16:55.538679 139984383674240 config_util.py:225] Writing pipeline config file to /content/gun_detection/models/research/fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yuxDnGPM_JPL","colab_type":"code","colab":{}},"source":["#downloads the frozen model that is needed for inference\n","files.download(output_directory + '/frozen_inference_graph.pb')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTkkaGq5BpYi","colab_type":"code","colab":{}},"source":["#downlaod the label map\n","files.download(DATA_BASE_PATH + '/label_map.pbtxt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYDDWHuwnO0E","colab_type":"code","colab":{}},"source":["files.download(output_directory + '/checkpoint')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXhzKrJ4nOgj","colab_type":"code","colab":{}},"source":["files.download(output_directory + '/model.ckpt.data-00000-of-00001')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PlOM7xHnOMb","colab_type":"code","colab":{}},"source":["files.download(output_directory + '/model.ckpt.index')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qGM8DoUnN6N","colab_type":"code","colab":{}},"source":["files.download(output_directory + '/model.ckpt.meta')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6LbHiBonNof","colab_type":"code","colab":{}},"source":["files.download(output_directory + '/pipeline.config')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TLe7LVXLnMaP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MOl520a_yJ0","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HBLXL57eiWf","colab_type":"code","colab":{}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnYXLeMh4yW4","colab_type":"code","colab":{}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4cg5doSE9Fb","colab_type":"code","colab":{}},"source":["!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDbD62S7eI41","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import tensorflow as tf\n","import cv2\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","# path to the frozen graph:\n","PATH_TO_FROZEN_GRAPH = '/content/gun_detection/models/research/frozen_inference_graph.pb'\n","\n","# path to the label map\n","PATH_TO_LABEL_MAP = '/content/gun_detection/models/research/label_map.pbtxt'\n","\n","# number of classes \n","NUM_CLASSES = 1\n","\n","cap = cv2.VideoCapture(0)\n","\n","#reads the frozen graph\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABEL_MAP)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","# Detection\n","with detection_graph.as_default():\n","    with tf.Session(graph=detection_graph) as sess:\n","        while True:\n","            # Read frame from camera\n","            ret, image_np = cap.read()\n","            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","            image_np_expanded = np.expand_dims(image_np, axis=0)\n","            # Extract image tensor\n","            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","            # Extract detection boxes\n","            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","            # Extract detection scores\n","            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","            # Extract detection classes\n","            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","            # Extract number of detections\n","            num_detections = detection_graph.get_tensor_by_name(\n","                'num_detections:0')\n","            # Actual detection.\n","            (boxes, scores, classes, num_detections) = sess.run(\n","                [boxes, scores, classes, num_detections],\n","                feed_dict={image_tensor: image_np_expanded})\n","            # Visualization of the results of a detection.\n","            vis_util.visualize_boxes_and_labels_on_image_array(\n","                image_np,\n","                np.squeeze(boxes),\n","                np.squeeze(classes).astype(np.int32),\n","                np.squeeze(scores),\n","                category_index,\n","                use_normalized_coordinates=True,\n","                line_thickness=3,\n","                )\n","        # Display output\n","            cv2.imshow('Gun Detection', cv2.resize(image_np, (1200, 800)))\n","            if cv2.waitKey(25) & 0xFF == ord('q'):\n","                cv2.destroyAllWindows()\n","                break"],"execution_count":0,"outputs":[]}]}